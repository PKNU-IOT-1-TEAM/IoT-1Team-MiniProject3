{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dqv2q2I1hisi"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "lunCIkzqigcj"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# Plots\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "# machine learning\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "from sklearn.model_selection import cross_val_score, RepeatedStratifiedKFold\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "MKjL73Q8hq3c"
      },
      "outputs": [],
      "source": [
        "# 데이터 부르기\n",
        "dfa = pd.read_csv('.\\dataset\\침수데이터.csv')\n",
        "dfb = pd.read_csv('.\\dataset\\호우데이터.csv')\n",
        "\n",
        "# 중복 제거\n",
        "dfa = dfa.drop_duplicates()\n",
        "dfb = dfb.drop_duplicates()\n",
        "dfb = dfb.drop(labels = \"습도(%)\", axis = 1)\n",
        "\n",
        "dfa['침수'] = 1\n",
        "dfb['침수'] = 0\n",
        "\n",
        "def replace_rainfall_with_mean(dataframe, column):\n",
        "    mean_value = dataframe[column][dataframe[column] != 0.0].mean()\n",
        "    dataframe[column] = dataframe[column].replace(0.0, mean_value)\n",
        "    return dataframe\n",
        "\n",
        "# 강수량(mm) 특성의 0.0 값을 평균값으로 대체\n",
        "column_to_replace = '강수량(mm)'\n",
        "dfa = replace_rainfall_with_mean(dfa, column_to_replace)\n",
        "\n",
        "df = pd.concat([dfa, dfb])\n",
        "df = df.drop(labels = '일시', axis = 1)\n",
        "\n",
        "df['기온(°C)'] = df['기온(°C)'].fillna(df['기온(°C)'].mean())\n",
        "df['풍향(deg)'] = df['풍향(deg)'].fillna(df['풍향(deg)'].mean())\n",
        "df['풍속(m/s)'] = df['풍속(m/s)'].fillna(df['풍속(m/s)'].mean())\n",
        "\n",
        "# # 정규화할 강수량 데이터가 담긴 열을 선택\n",
        "# rainfall_data = df['강수량(mm)']\n",
        "\n",
        "# # Min-Max 정규화 객체 생성\n",
        "# min_max_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
        "\n",
        "# # 강수량 데이터를 Min-Max 정규화\n",
        "# normalized_data = min_max_scaler.fit_transform(rainfall_data.values.reshape(-1, 1))\n",
        "\n",
        "# # 표준화 객체 생성\n",
        "# standard_scaler = StandardScaler()\n",
        "\n",
        "# # Min-Max 정규화된 데이터를 표준화\n",
        "# standardized_data = standard_scaler.fit_transform(normalized_data)\n",
        "\n",
        "# # 정규화된 데이터를 새로운 열로 추가\n",
        "# df['강수량_정규화'] = normalized_data.flatten()\n",
        "# df['강수량_표준화'] = standardized_data.flatten()\n",
        "\n",
        "X = df.drop(labels = ['침수'], axis = 1)\n",
        "y = df['침수']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "2r8lkRg6jmYL"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8349378881987578"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "logreg = LogisticRegression()\n",
        "logreg.fit(X_train, y_train)\n",
        "\n",
        "logreg_y_pred = logreg.predict(X_test)\n",
        "logreg_accuracy = logreg.score(X_train, y_train)\n",
        "logreg_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "yazoctrykq6j"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8658593386120168"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "base_models = [\n",
        "    ('svc', SVC()),\n",
        "    ('gnb', GaussianNB()),\n",
        "    ('mlp', MLPClassifier())\n",
        "]\n",
        "\n",
        "stacking_model = StackingClassifier(estimators=base_models)\n",
        "\n",
        "# StackingClassifier 훈련\n",
        "stacking_model.fit(X_train, y_train)\n",
        "\n",
        "# StackingClassifier 예측\n",
        "predictions = stacking_model.predict(X_test)\n",
        "stacking_model.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "_feOctOfl3YD"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test AUC for class \"1\":\n",
            "0.9465864813030989\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "class_index = 1\n",
        "y_pred_proba = stacking_model.predict_proba(X_val)[:, class_index]\n",
        "print(f'Test AUC for class \"{stacking_model.classes_[class_index]}\":')\n",
        "print(roc_auc_score(y_val, y_pred_proba)) # 범위는 0-1, 수치는 높을 수록 좋습니다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "VM6jhg4lmeoC"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.83      0.86      1065\n",
            "           1       0.84      0.89      0.87      1082\n",
            "\n",
            "    accuracy                           0.86      2147\n",
            "   macro avg       0.86      0.86      0.86      2147\n",
            "weighted avg       0.86      0.86      0.86      2147\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y_test_pred = stacking_model.predict(X_val)\n",
        "print(classification_report(y_val, y_test_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "8-Fg7XmOmp1r"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0]\n",
            "[[0.96945927 0.03054073]]\n"
          ]
        }
      ],
      "source": [
        "from joblib import dump, load\n",
        "\n",
        "# 훈련된 모델 저장\n",
        "dump(stacking_model, 'stacking_model.joblib')\n",
        "\n",
        "# 저장된 모델 로드\n",
        "loaded_stacking = load('stacking_model.joblib')\n",
        "\n",
        "data = {\n",
        "    '기온(°C)': [22.6],\n",
        "    '풍향(deg)': [43.0],\n",
        "    '풍속(m/s)': [0.8],\n",
        "    '강수량(mm)': [0.0]\n",
        "}\n",
        "\n",
        "new_data = pd.DataFrame(data)\n",
        "\n",
        "# # 정규화할 강수량 데이터가 담긴 열을 선택\n",
        "# rainfall_data = new_data['강수량(mm)']\n",
        "\n",
        "# # Min-Max 정규화 객체 생성\n",
        "# min_max_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
        "\n",
        "# # 강수량 데이터를 Min-Max 정규화\n",
        "# normalized_data = min_max_scaler.fit_transform(rainfall_data.values.reshape(-1, 1))\n",
        "\n",
        "# # 표준화 객체 생성\n",
        "# standard_scaler = StandardScaler()\n",
        "\n",
        "# # Min-Max 정규화된 데이터를 표준화\n",
        "# standardized_data = standard_scaler.fit_transform(normalized_data)\n",
        "\n",
        "# # 정규화된 데이터를 새로운 열로 추가\n",
        "# new_data['강수량_정규화'] = normalized_data.flatten()\n",
        "# new_data['강수량_표준화'] = standardized_data.flatten()\n",
        "\n",
        "# new_data = new_data.drop(labels = '강수량(mm)', axis= 1)\n",
        "predictions = loaded_stacking.predict(new_data)\n",
        "\n",
        "probabilities = stacking_model.predict_proba(new_data)\n",
        "print(predictions)\n",
        "print(probabilities)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
