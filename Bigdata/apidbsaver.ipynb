{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import\n",
    "import pymysql \n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "from joblib import load\n",
    "from urllib.parse import unquote, urlencode, quote_plus \n",
    "from datetime import datetime, date, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\DEV\\Langs\\Python311\\Lib\\site-packages\\sklearn\\base.py:347: InconsistentVersionWarning: Trying to unpickle estimator SVC from version 1.2.2 when using version 1.3.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\DEV\\Langs\\Python311\\Lib\\site-packages\\sklearn\\base.py:347: InconsistentVersionWarning: Trying to unpickle estimator GaussianNB from version 1.2.2 when using version 1.3.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\DEV\\Langs\\Python311\\Lib\\site-packages\\sklearn\\base.py:347: InconsistentVersionWarning: Trying to unpickle estimator MLPClassifier from version 1.2.2 when using version 1.3.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\DEV\\Langs\\Python311\\Lib\\site-packages\\sklearn\\base.py:347: InconsistentVersionWarning: Trying to unpickle estimator LabelEncoder from version 1.2.2 when using version 1.3.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\DEV\\Langs\\Python311\\Lib\\site-packages\\sklearn\\base.py:347: InconsistentVersionWarning: Trying to unpickle estimator LogisticRegression from version 1.2.2 when using version 1.3.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\DEV\\Langs\\Python311\\Lib\\site-packages\\sklearn\\base.py:347: InconsistentVersionWarning: Trying to unpickle estimator LabelBinarizer from version 1.2.2 when using version 1.3.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\DEV\\Langs\\Python311\\Lib\\site-packages\\sklearn\\base.py:347: InconsistentVersionWarning: Trying to unpickle estimator StackingClassifier from version 1.2.2 when using version 1.3.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "live_url = \"https://apis.data.go.kr/1360000/VilageFcstInfoService_2.0/getUltraSrtNcst\"\n",
    "short_predict= \"https://apis.data.go.kr/1360000/VilageFcstInfoService_2.0/getUltraSrtFcst\" # 초단기 예보 (저장용)\n",
    "\n",
    "serviceKey = \"wGokgRxD1t3z5G4u7MsWumpoCeiWO8JM6yZ87rX1ELTO9nMSUuMOQjHj70rAzuopgyB1iLdKX0S9WK0RLs88bQ==\" # 공공데이터 포털에서 생성된 본인의 서비스 키를 복사 / 붙여넣기\n",
    "serviceKeyDecoded = unquote(serviceKey, 'UTF-8') # 공공데이터 포털에서 제공하는 서비스키는 이미 인코딩된 상태이므로, 디코딩하여 사용해야 함 -> 초단기 실황(예보도 동일)\n",
    "\n",
    "stacking = load('model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_Time():\n",
    "    now = datetime.now()\n",
    "    base_time = \"\"\n",
    "\n",
    "    if  now.minute > 0 and now.minute < 30 :\n",
    "        base_time = f\"{now.hour-1:02d}30\"\n",
    "    \n",
    "    elif now.minute > 30:\n",
    "         base_time = f\"{now.hour-1:02d}00\"\n",
    "\n",
    "    return base_time\n",
    "\n",
    "def base_Date():\n",
    "    today = datetime.today()\n",
    "    y = today- timedelta(days=1)\n",
    "    base_date = today.strftime(\"%Y%m%d\")\n",
    "\n",
    "    return base_date\n",
    "\n",
    "def api_load(url, serviceKey):\n",
    "    base_time = base_Time()\n",
    "    #'1130' -> 시간 조금 손봐야함  \n",
    "    base_date = base_Date()\n",
    "    #'20230803' -> 시간 조금 손봐야함 \n",
    "\n",
    "    serviceKeyDecoded = unquote(serviceKey, 'UTF-8')\n",
    "\n",
    "    queryParams = '?' + urlencode({quote_plus('serviceKey') : serviceKeyDecoded, quote_plus('base_date') : base_date, quote_plus('pageNo') : 1,\n",
    "                                        quote_plus('base_time') : base_time, quote_plus('nx') : 98, quote_plus('ny') : 76,\n",
    "                                        quote_plus('dataType') : 'json', quote_plus('numOfRows') : '60'}) #페이지로 안나누고 한번에 받아오기 위해 numOfRows=60으로 설정해주었다\n",
    "\n",
    "    res = requests.get(url + queryParams, verify=False)\n",
    "    data = res.json().get('response').get('body').get('items')\n",
    "\n",
    "    return data\n",
    "\n",
    "def get_predict():\n",
    "  live_data = api_load(live_url, serviceKey)\n",
    "  data = {\n",
    "        'basedate' : [live_data['item'][0]['baseDate']],\n",
    "        'basetime' : [live_data['item'][0]['baseTime']],\n",
    "        '기온(°C)': [float(live_data['item'][3]['obsrValue'])],\n",
    "        '풍향(deg)': [float(live_data['item'][5]['obsrValue'])],\n",
    "        '풍속(m/s)': [float(live_data['item'][7]['obsrValue'])],\n",
    "        '강수량(mm)': [float(live_data['item'][2]['obsrValue'])]\n",
    "    }\n",
    "\n",
    "  new_data = pd.DataFrame(data)\n",
    "  probabilities = stacking.predict_proba(new_data.drop(columns = ['basedate', 'basetime']))\n",
    "\n",
    "  return round(probabilities[0][1] * 100, 2), data\n",
    "\n",
    "def get_forecast():\n",
    "    data = api_load(short_predict, serviceKey)\n",
    "    weather_data = dict()\n",
    "\n",
    "    for item in data['item']:\n",
    "        Date = item['fcstDate']\n",
    "        Time = item['fcstTime']\n",
    "        if item['fcstDate'] not in weather_data:\n",
    "            weather_data[Date] = dict()\n",
    "        if item['fcstTime'] not in weather_data[Date]:\n",
    "            weather_data[Date][Time] = dict()\n",
    "\n",
    "        if item['category'] == \"T1H\":\n",
    "            weather_data[Date][Time]['T1H'] = item['fcstValue']\n",
    "        elif item['category'] == \"RN1\":\n",
    "            weather_data[Date][Time]['RN1'] = item['fcstValue']\n",
    "        elif item['category'] == \"SKY\":\n",
    "            weather_data[Date][Time][\"SKY\"] = item['fcstValue']\n",
    "        elif item['category'] == \"UUU\":\n",
    "            weather_data[Date][Time]['UUU'] = item['fcstValue']\n",
    "        elif item['category'] == \"VVV\":\n",
    "            weather_data[Date][Time]['VVV'] = item['fcstValue']\n",
    "        elif item['category'] == \"REH\":\n",
    "            weather_data[Date][Time]['REH'] = item['fcstValue']\n",
    "        elif item['category'] == \"PTY\":\n",
    "            weather_data[Date][Time]['PTY'] = item['fcstValue']\n",
    "        elif item['category'] == \"LGT\":\n",
    "            weather_data[Date][Time]['LGT'] = item['fcstValue']\n",
    "        elif item['category'] == \"VEC\":\n",
    "            weather_data[Date][Time]['VEC'] = item['fcstValue']\n",
    "        elif item['category'] == 'WSD':\n",
    "            weather_data[Date][Time]['WSD'] = item['fcstValue']\n",
    "\n",
    "    return weather_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최적화 전\n",
    "\n",
    "def connect_to_DB():\n",
    "    conn = pymysql.connect(\n",
    "        host = '210.119.12.112',\n",
    "        port = 10000,\n",
    "        user = 'pi',\n",
    "        password = '12345',\n",
    "        database = 'team1_iot'\n",
    "    )\n",
    "    return conn\n",
    "\n",
    "def UpdateDB(weather_data):\n",
    "    try:\n",
    "        for day in weather_data:\n",
    "            for time in weather_data[day]:\n",
    "                conn = connect_to_DB()\n",
    "                cur = conn.cursor()\n",
    "                query = '''UPDATE ultrasrtfcst SET \n",
    "                                T1H = %s, RN1 = %s, SKY = %s,\n",
    "                                UUU = %s, VVV = %s, REH = %s,\n",
    "                                PTY = %s, LGT = %s, VEC = %s, \n",
    "                                WSD = %s, BaseDate = %s, BaseTime = %s  WHERE fcstDate = %s AND fcstTime = %s '''\n",
    "                \n",
    "                tmp_day = day[0:4] + '-' + day[4:6] + '-' + day[6:]\n",
    "                tmp_time = time[0:2] + ':' + time[2:]\n",
    "\n",
    "                bday = base_Date()[0:4] + '-' + base_Date()[4:6] + '-' + base_Date()[6:]\n",
    "                btime = base_Time()[0:2] + ':' + base_Time()[2:]\n",
    "\n",
    "                cur.execute(query, (weather_data[day][time]['T1H'],weather_data[day][time]['RN1'],weather_data[day][time]['SKY'],weather_data[day][time]['UUU'],\n",
    "                                    weather_data[day][time]['VVV'],weather_data[day][time]['REH'],weather_data[day][time]['PTY'],weather_data[day][time]['LGT'],\n",
    "                                    weather_data[day][time]['VEC'],weather_data[day][time]['WSD'], bday, btime, tmp_day, tmp_time))\n",
    "                conn.commit()\n",
    "        conn.close()\n",
    "        print('수정 완료')\n",
    "    except Exception as e:\n",
    "        print(f'{e}')\n",
    "\n",
    "def InsertDB(weather_data):\n",
    "    try:\n",
    "        for day in weather_data:\n",
    "            for time in weather_data[day]:\n",
    "                conn = connect_to_DB()\n",
    "                cur = conn.cursor()\n",
    "\n",
    "                tmp_day = day[0:4] + '-' + day[4:6] + '-' + day[6:]\n",
    "                tmp_time = time[0:2] + ':' + time[2:]\n",
    "\n",
    "                bday = base_Date()[0:4] + '-' + base_Date()[4:6] + '-' + base_Date()[6:]\n",
    "                btime = base_Time()[0:2] + ':' + base_Time()[2:]\n",
    "\n",
    "                total_qry = f\"\"\"INSERT INTO ultrasrtfcst\n",
    "                                (fcstDate, fcstTime, BaseDate, BaseTime, T1H, RN1, SKY, UUU, VVV, REH, PTY, LGT, VEC, WSD) VALUES\n",
    "                                 ('{tmp_day}', '{tmp_time}', '{bday}', '{btime}', {weather_data[day][time]['T1H']}, \n",
    "                                  '{weather_data[day][time]['RN1']}', '{weather_data[day][time]['SKY']}', {weather_data[day][time]['UUU']}, \n",
    "                                  {weather_data[day][time]['VVV']}, {weather_data[day][time]['REH']}, '{weather_data[day][time]['PTY']}',\n",
    "                                  {weather_data[day][time]['LGT']}, {weather_data[day][time]['VEC']}, {weather_data[day][time]['WSD']})\"\"\"\n",
    "                \n",
    "                cur.execute(total_qry)\n",
    "                # cur.execute(query, (tmp_day, tmp_time, weather_data[day][time]['T1H'],weather_data[day][time]['RN1'],weather_data[day][time]['SKY'],weather_data[day][time]['UUU'],\n",
    "                #                     weather_data[day][time]['VVV'],weather_data[day][time]['REH'],weather_data[day][time]['PTY'],weather_data[day][time]['LGT'],\n",
    "                #                     weather_data[day][time]['VEC'],weather_data[day][time]['WSD']))\n",
    "                conn.commit()\n",
    "        conn.close()\n",
    "        print('입력 완료')\n",
    "    except Exception as e:\n",
    "        print(f'{e}')\n",
    "\n",
    "def InsertPredictDB():\n",
    "    try:\n",
    "        conn = connect_to_DB()\n",
    "        cur = conn.cursor()\n",
    "\n",
    "        predict, live_data = get_predict()\n",
    "\n",
    "        bday = live_data['basedate'][0][0:4] + '-' + live_data['basedate'][0][4:6] + '-' + live_data['basedate'][0][6:]\n",
    "        btime = live_data['basetime'][0][0:2] + ':' + live_data['basetime'][0][2:]\n",
    "\n",
    "        total_qry = f\"\"\"INSERT INTO predict\n",
    "                        (predict, basedate, basetime, temp, deg, rain, windspeed) VALUES\n",
    "                            ('{predict}', '{bday}', '{btime}', '{live_data['기온(°C)'][0]}', '{live_data['풍향(deg)'][0]}','{live_data['강수량(mm)'][0]}', '{live_data['풍속(m/s)'][0]}')\"\"\"\n",
    "        \n",
    "        cur.execute(total_qry)\n",
    "        conn.commit()\n",
    "        conn.close()\n",
    "        print('입력 완료')\n",
    "    except Exception as e:\n",
    "        print(f'{e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_to_DB():\n",
    "    conn = pymysql.connect(\n",
    "        host = '210.119.12.112',\n",
    "        port = 10000,\n",
    "        user = 'pi',\n",
    "        password = '12345',\n",
    "        database = 'team1_iot'\n",
    "    )\n",
    "    return conn\n",
    "\n",
    "def InsertDB(input_data, tmp_day, tmp_time, bday, btime):\n",
    "    try:\n",
    "        conn = connect_to_DB()\n",
    "        cur = conn.cursor()\n",
    "\n",
    "        total_qry = f\"\"\"INSERT INTO ultrasrtfcst\n",
    "                        (fcstDate, fcstTime, BaseDate, BaseTime, T1H, RN1, SKY, UUU, VVV, REH, PTY, LGT, VEC, WSD) VALUES\n",
    "                            ('{tmp_day}', '{tmp_time}', '{bday}', '{btime}', {input_data['T1H']}, \n",
    "                            '{input_data['RN1']}', '{input_data['SKY']}', {input_data['UUU']}, \n",
    "                            {input_data['VVV']}, {input_data['REH']}, '{input_data['PTY']}',\n",
    "                            {input_data['LGT']}, {input_data['VEC']}, {input_data['WSD']})\"\"\"\n",
    "        \n",
    "        cur.execute(total_qry)\n",
    "\n",
    "        conn.commit()\n",
    "        conn.close()\n",
    "    except Exception as e:\n",
    "        print(f'{e}')\n",
    "\n",
    "def UpdateDB(input_data, tmp_day, tmp_time, bday, btime):\n",
    "    try:\n",
    "        conn = connect_to_DB()\n",
    "        cur = conn.cursor()\n",
    "        query = '''UPDATE ultrasrtfcst SET \n",
    "                        T1H = %s, RN1 = %s, SKY = %s,\n",
    "                        UUU = %s, VVV = %s, REH = %s,\n",
    "                        PTY = %s, LGT = %s, VEC = %s, \n",
    "                        WSD = %s, BaseDate = %s, BaseTime = %s  WHERE fcstDate = %s AND fcstTime = %s '''\n",
    "        \n",
    "        cur.execute(query, (input_data['T1H'],input_data['RN1'],input_data['SKY'],input_data['UUU'],\n",
    "                            input_data['VVV'],input_data['REH'],input_data['PTY'],input_data['LGT'],\n",
    "                            input_data['VEC'],input_data['WSD'], bday, btime, tmp_day, tmp_time))\n",
    "        conn.commit()\n",
    "        conn.close()\n",
    "    except Exception as e:\n",
    "        print(f'{e}')\n",
    "\n",
    "\n",
    "def InsertPredictDB():\n",
    "    try:\n",
    "        conn = connect_to_DB()\n",
    "        cur = conn.cursor()\n",
    "\n",
    "        predict, live_data = get_predict()\n",
    "\n",
    "        bday = live_data['basedate'][0][0:4] + '-' + live_data['basedate'][0][4:6] + '-' + live_data['basedate'][0][6:]\n",
    "        btime = live_data['basetime'][0][0:2] + ':' + live_data['basetime'][0][2:] + \":00\"\n",
    "\n",
    "        search_query = f'''\n",
    "                        SELECT EXISTS (SELECT Idx FROM predict WHERE BaseDate = '{bday}' and BaseTime = '{btime}') AS SUCCESS;\n",
    "                        '''\n",
    "        cur.execute(search_query)        \n",
    "        result = cur.fetchone()[0]\n",
    "\n",
    "        if result == 0 :\n",
    "            total_qry = f\"\"\"INSERT INTO predict\n",
    "                            (predict, basedate, basetime, temp, deg, rain, windspeed) VALUES\n",
    "                                ('{predict}', '{bday}', '{btime}', '{live_data['기온(°C)'][0]}', '{live_data['풍향(deg)'][0]}','{live_data['강수량(mm)'][0]}', '{live_data['풍속(m/s)'][0]}')\"\"\"\n",
    "    \n",
    "            cur.execute(total_qry)\n",
    "        conn.commit()\n",
    "        conn.close()\n",
    "    except Exception as e:\n",
    "        print(f'{e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weather_data_insert(weather_data):\n",
    "    for day in weather_data:\n",
    "        for time in weather_data[day]:\n",
    "            conn = connect_to_DB()\n",
    "            cur = conn.cursor()\n",
    "            \n",
    "            tmp_day = day[0:4] + '-' + day[4:6] + '-' + day[6:]\n",
    "            tmp_time = time[0:2] + ':' + time[2:]\n",
    "            \n",
    "            bday = base_Date()[0:4] + '-' + base_Date()[4:6] + '-' + base_Date()[6:]\n",
    "            btime = base_Time()[0:2] + ':' + base_Time()[2:] + ':00'\n",
    "            \n",
    "            search_query = f'''\n",
    "                            SELECT EXISTS (SELECT Idx FROM ultrasrtfcst WHERE FcstDate = '{tmp_day}' and FcstTime = '{tmp_time}' and BaseDate = '{bday}' and BaseTime = '{btime}') AS SUCCESS;\n",
    "                            '''\n",
    "            cur.execute(search_query)        \n",
    "            result = cur.fetchone()[0]\n",
    "            conn.close()\n",
    "            \n",
    "            input_data = weather_data[day][time]\n",
    "            if result == 1 :\n",
    "                UpdateDB(input_data, tmp_day, tmp_time, bday, btime) \n",
    "            else :\n",
    "                InsertDB(input_data, tmp_day, tmp_time, bday, btime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\DEV\\Langs\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'apis.data.go.kr'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "c:\\DEV\\Langs\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'apis.data.go.kr'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    conn = connect_to_DB()\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    weather_data = get_forecast()\n",
    "    weather_data_insert(weather_data)\n",
    "    InsertPredictDB()\n",
    "    \n",
    "    conn.commit()\n",
    "    conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
